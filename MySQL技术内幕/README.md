# MySQL 技术内幕

## MySQL 体系结构和存储引擎
- 数据库：物理操作系统文件或其他形式**文件**类型的集合
- 实例：MySQL 数据库由后台线程以及一个共享内存区组成，共享内存区可以被运行的后台线程所共享，数据库实例才是真正用于操作数据库文件的（**程序**）
- InnoDB 存储引擎
  - **行级锁、支持外键、非锁定读（默认读操作不加锁）**
  - 支持四种隔离级别，默认为 REPEATABLE，使用一种叫 `next-key locking` 策略来避免幻读
  - 提供插入缓冲、二次写、自适应哈希索引、预读
  - 采用聚集索引，每张表的存储都按主键的顺序进行存放
- MyISAM 存储引擎
  - 不支持事务、表级锁、支持全文索引
  - 缓冲池只缓冲索引文件，不缓冲数据文件
- NDB 存储引擎
  - 数据全部存放在内存中（v5.1 之后，可以将非索引文件放在磁盘上）
  - 连接操作在 Server 层完成，而不是存储引擎层
- Memory 存储引擎
  - 表中数据存放在内存中
  - 适合于存储临时表，默认使用哈希索引（而不是 B+ 树）
  - 只支持表锁，变长字段按照定长字段存储

## InnoDB 存储引擎
### InnoDB 体系结构：

```mermaid
graph LR;
subgraph innodb;
  A(后台线程)-.-B(后台线程);
  B(后台线程)-.-C(后台线程);
  C(后台线程)-.-D(后台线程);
  E[InnoDB 存储引擎内存池];
end;
F[文件]-.-G[文件];
G[文件]-.-H[文件];
H[文件]-.-I[文件];
```
InnoDB 存储引擎有多个内存块，这些内存块组成了一个大的内存池
- 维护所有进程/线程需要访问的多个内部数据结构
- 缓存磁盘上的数据，方便快速地读取，同时在对磁盘文件的数据修改之前在这里缓存
- 重做日志（redo log）缓冲

后台线程的主要作用是**负责刷新内存池中的数据，保证缓冲池中的内存缓冲的是最近的数据**。此外**将已修改的数据文件刷新到磁盘文件，同时保证在数据库发生异常的情况下 InnoDB 能恢复到正常运行状态**

#### 后台线程

- **Master Thread**：核心线程，主要负责**将缓冲池中的数据异步刷新到磁盘**，保证数据的一致性。包括**脏页的刷新、合并插入缓冲、undo 页的回收**等。
- IO Thread：负责 IO 请求的回调处理
  - write thread
  - read thread
  - insert buffer thread
  - log IO thread
- Purge Thread：事务被提交后，其所使用的 undo log 可能不再需要，因此需要该线程来**回收已经使用并分配的 undo 页**
- Page Cleaner Thread：负责脏页的刷新

#### 内存

```mermaid
  graph LR;
  A[重做日志缓冲];
  B[额外内存池];
  A-.-B;
  subgraph innodb_buffer_pool;
  C[数据页];
  D[索引页];
  E[插入缓冲];
  F[自适应哈希索引];
  G[锁信息];
  C-.-D;
  E-.-F-.-G;
  end;
```

- **缓冲池**：一块内存区域，通过内存的数据来弥补磁盘 IO 的速度。读取时，将页缓存在缓冲池中；修改时，先修改缓冲池中的页，然后再以一定的频率刷新到磁盘上

	- 缓冲池中缓存的页类型有：**索引页、数据页、undo 页、插入缓冲、自适应哈希索引、InnoDB 存储的锁信息、数据字典信息**等
	- 缓冲池通过 LRU 算法来管理，页的默认大小为 16KB。LRU 列表中还加入了 midpoint 位置，新读取到的页放入 midpoint 位置而不是首部(midpoint insertion strategy)，防止某些只用一次的页占据了首部的位置
	- 参数 `innodb_old_blocks_time` 限制页被加入到 mid 位置后至少需要多久才能被加入 LRU 的热端
	- InnoDB 1.0.x 版本开始支持压缩页的功能，通过 unzip_LRU 列表对不同压缩页的大小进行分别管理（伙伴算法）
  > 假设需要对缓冲池申请页为 4KB 的大小，过程：
  >
  > 1. 检查 4KB 的 unzip_LRU 列表，检查是否有可用的空闲页；
  > 2. 若有，直接使用；
  > 3. 否则，检查 8KB 的 unzip_LRU 列表
  > 4. 若有，将页分成 2 个 4KB 页，存放到 4KB 的 unzip_LRU 列表
  > 5. 否则，从 LRU 列表中申请一个 16KB 的页，将页分为 1 个 8KB 的页、2 个 4KB 的页，分别存放到对应的 unzip_LRU 列表中
- 脏页：LRU 列表中被修改后的页，即缓冲池中的页和磁盘上的页数据不一致。这时数据库会通过 CHECKPOINT 机制将脏页刷新回磁盘，而 Flush 列表中的页即为脏页列表（脏页既存在于 LRU 列表中，也存在于 Flush 列表中，LRU 列表用来管理缓冲池中页的可用性，Flush 列表用来管理将页刷新回磁盘）
- **<a id='redoLogBuffer'>重做日志缓冲（redo log buffer）</a>**：InnoDB 存储引擎首先将重做日志信息先放入到这个缓冲区，然后按一定频率刷新到重做日志文件（一般每秒刷入，因此用户只要保证这个缓冲区大小大于每秒产生的事务量）。
	
  - 刷新到日志文件的时机
    - Master Thread 每秒将其刷进
    - 每个事务提交时
    - 重做日志缓冲区剩余空间小于 1/2 时
- **额外的内存池**：在对一些**数据结构本身的内存**进行分配时，需要从额外的内存池中进行申请，当该区域的内存不够时，会从缓冲池中进行申请。

### CheckPoint 技术

- 为避免发生数据丢失的问题，当前事务数据库系统普遍都采用了 Write Ahead Log 策略：**即当事务提交时，先写重做日志，再修改页**。当由于发生宕机而导致数据丢失时，通过重做日志来完成数据的修复（事务的持久性）
- CheckPoint 技术的目的：
  - 缩短数据库的恢复时间
  - 缓冲池不够用时，将淘汰的脏页刷新到磁盘
  - 重做日志不可用时，刷新脏页（让缓冲池的页刷新到当前重做日志的位置，以便重做日志的覆盖重用）
- 当数据库发生宕机时，不用重做所有的日志，因为 CheckPoint 之前的页都已经刷新回磁盘，只需要对 CheckPoint 后的重做日志进行恢复
- **Sharp Checkpoint**：发生在数据库关闭时将所有的脏页都刷新回磁盘
- **Fuzzy Checkpoint**：只刷新一部分脏页，包括：
  - **Master Thread Checkpoint**：差不多以每秒或每十秒的速度从缓冲池的脏页列表中刷新一定比例的页回磁盘。这个过程是异步的，即此时 InnoDB 存储引擎可以进行其他的操作，用户查询线程不会阻塞。
  - **FLUSH_LRU_LIST Checkpoint**：需要保证 LRU 列表中有差不多 100 个空闲页可供使用，如果没有，则移除列表尾部的页，如果其中有脏页，则进行 Checkpoint（InnoDB 1.1.x 之前，检查 LRU 列表中是否有足够空间发生在用户查询线程中，会阻塞查询；1.2.x 开始，该检查被放在一个单独的 Page Cleaner 线程中进行）
  - <a id='asyncCheckpoint'>**Async/Sync Flush Checkpoint**</a>：重做日志不可用的情况，此时脏页是从脏页列表(Flush)中选取的（InnoDB 1.2.x 之前，会阻塞用户查询线程；1.2.x 开始，这部分的刷新操作被放入到了单独的 Page Cleaner 线程中进行）
  - **Dirty Page too much**：脏页数量太多，强制进行 Checkpoint

### Master Thread 工作方式
- 1.0.x 之前，内部循环：
  
  - **主循环**：
    - 每秒一次的操作：
      - 重做日志缓冲刷新到重做日志文件，即使这个事务还没有提交（必须）
      - 合并插入缓冲（可能，前一秒内 IO 次数小于 5 次）
      - 至多刷新 100 个 InnoDB 的缓冲池中的脏页到磁盘（可能，如果脏页过多）
      - 如果当前没有用户活动，则切换到后台循环
    - 十秒一次的操作：
      - 刷新 100 个脏页到磁盘（可能，过去十秒 IO 操作小于 200 次）
      - 合并至多 5 个插入缓冲（总是）
      - 将日志缓冲刷新到磁盘（日志文件）（总是）
      - 删除无用的 undo 页（最多尝试回收 20 个 undo 页），例如真正执行 update、delete（可能之前只是修改了版本号）
      - 刷新 100 个或者 10% 的脏页到磁盘（总是，超过 70%，则 100 个，否则 10%）
  - **后台循环**：当前没有用户活动（数据库空闲）或者数据库关闭时
    - 删除无用的 undo 页（总是）
    - 合并 20 个插入缓冲（总是）
    - 跳回到主循环（总是）
    - 不断刷新 100 个页直到符合条件（可能，跳转到刷新循环中完成）
  - **刷新循环**
    - 切换到暂停循环，将主循环挂起，等待事件的发生
  - **暂停循环**
  ```c
  void master_thread() {
      goto loop;
  loop:
      for (int i = 0; i < 10; i++) {
          thread_sleep(1)
          do log buffer flush to disk
          if (last_one_second_ios < 5) {
              do merge at most 5 insert buffer
          }
          if (buf_get_modified_ratio_pct > innodb_max_dirty_pages_pct) {
              do buffer pool flush 100 dirty pages
          }
          if (no user activity) {
              goto background loop
          }
      }
      if (last_ten_second_ios < 200) {
          do buffer pool flush 100 dirty pages
      } 
      do merge at most 5 insert buffer
      do log buffer flush to disk
      do full purge
      if (buf_get_modified_ratio_pct > 70%) {
          do buffer pool flush 100 dirty pages
      } else {
          buffer pool flush 10% dirty pages
      }
  
      goto loop
  
  background loop:
      do full purge
      do merge 20 insert buffer
      if (!idle) {
          goto loop
      } else {
          goto flush loop
      }
  
  flush loop:
      do buffer pool flush 100 dirty pages
      if (buf_get_modified_ratio_pct > innodb_max_dirty_pages_pct) {
          goto flush loop
      }
      goto suspend loop
  
  suspend loop:
      suspned_thread()
      waiting event
  
      goto loop
  }
  ```
  
- 1.0.x - 1.2.x 版本：在 1.0.x 之前，最多刷新 100 个脏页、合并 20 个插入缓存等硬编码，已不适合现在的硬件。
  
  - 1.2.x 之前通过参数 `innodb_io_capacity` 来表示磁盘的吞吐量，对于刷新到磁盘页的数量，会按照 `innodb_io_capacity` 的百分比来控制：合并插入缓存为 5%，从缓冲区刷新脏页为 100%
  - 脏页比例阈值 `innodb_max_dirty_pages_cnt` 从 90 改为 75，这样既能加快刷新脏页的频率，又能保证磁盘 IO 的负载
  - 自适应刷新参数 `innodb_adaptive_flushing`，通过判断产生重做日志的速度来决定最合适的刷新脏页数量
  - 通过参数 `innodb_purge_batch_size` 控制回收的 undo 页的数量
  
- 1.2.x 版本：
  
  ```c
    if (InnoDB is idle) {
        srv_master_do_idle_tasks(); // 10 秒的操作
    } else {
        srv_master_do_active_tasks(); // 每秒的操作
    }
  ```
  同时将刷新脏页的操作单独分配到 Page Cleaner 线程中


### 关键特性

- **插入缓冲（Insert Buffer）**：在缓冲池中，与数据页一样，也是物理页的一个组成部分。对于**非聚集索引**的插入或更新操作，不是每一次直接插入到索引页中，而是先判断插入的非聚集索引页是否在缓冲池中，若在，则直接插入；若不在，则先放入到一个 Insert Buffer 对象中，然后再以一定的频率和情况进行 Insert Buffer 和（非聚集的）辅助索引页子节点的合并操作，这时通常能将多个插入合并到一个操作中（因为在一个索引页中）

  需要同时满足两个条件：**索引是非聚集的辅助索引**（如果是聚集索引（主键索引），那么是按顺序插入的，不需要随机访问）；**索引不是唯一的**（因为在插入缓冲时，数据库并不去查找索引页来判断插入的记录的唯一性，如果又去查找则又必然会进行随机读取，导致插入缓冲失去意义。

  - Change Buffer：1.0.x 版本开始引入，可将其视为 Insert Buffer 的升级，它可以使得 DML 操作——Insert、Delete（Delete Buffer）、Update（Purge Buffer） 都进行缓冲。它的对象依然是非唯一的辅助索引。

  - Insert Buffer 内部原理：**所有表共享一棵 Insert Buffer B+ 树，存放在共享表空间中**。

      非叶节点：存放 search key：`|space(4B)|marker(1B)|offset(4B)|`，space 是每个表的 id，marker 用于兼容老版本 Insert Buffer，offset 表示页所在偏移量。

      叶子节点：

      ```
      |space(4B)|marker(1B)|offset(4B)|metadata(4B)|data..|
          																|
          																|
      |IBUF_REC_OFFSET_COUNT(用于记录插入顺序)|IBUF_REC_OFFSET_TYPE|IBUF_REC_OFFSET_FLAGS|
      ```

      Insert Buffer Bitmap：一个特殊的页，用于标记每个辅助索引页的可用空间，每个辅助索引页在其中占用 4 bit，存放在独立表空间中

      ```c
      IBUF_BITMAP_FREE(2b) // 表示可用空间数量 
      IBUF_BITMAP_BUFFERED(1b) // 表示该辅助索引页有记录被缓存在 Insert Buffer B+ 树中
      IBUF_BITMAP_IBUF(1b) // 表示该页为 Insert Buffer B+ 树的索引页
      ```

  - Merge Insert Buffer：

      操作发生的时间：
      - 辅助索引页被读取到缓冲池时；
      - Insert Buffer Bitmap 页追踪到该辅助索引页已无可用空间时；
      - Master Thread：随机选择 Insert Buffer B+ 树的一个页，读取该页中的 space 及之后所需要数量的页（该算法在复杂情况下有更好的公平性）


- **<a id='doubleWrite'>两次写（Double Write）</a>**：内存中有 doublewrite buffer（2MB），物理磁盘上共享表空间中有 2 个区（2MB）的 doublewrite。

    - 缓冲池刷新脏页时，将脏页复制到 doublewrite buffer 中（而不是直接写入磁盘）
    - 之后通过 doublewrite buffer 再分两次，每次 1MB 顺序地写入 doublewrite，然后马上调用 fsync 函数，同步磁盘，避免缓冲写带来的问题
    - 完成 doublewrite 页的写入后，再将 doublewrite buffer 中的页离散地写入各个表空间文件中

  ```mermaid
  graph LR;
  subgraph memory;
  	A[page]-.copy.->B[doublewrite buffer 2MB];
    C[page]-.copy.->B;
  end;
  subgraph shared_table;
  	D[doublewrite 1MB]-.-E[doublewrite 1MB]
  end;
  B-.write.->D
  B-.write.->F
  subgraph data;
  F(data)-.-G(data)-.-H(data)
  end;
  E-.recovery.->F
  ```

    - 好处在于写入磁盘崩溃时，可以通过共享表空间中的 doublewrite 副本恢复


- **自适应哈希索引（Adaptive Hash Index）**：InnoDB 存储引擎会监控对表上各索引页的查询，如果观察到建立哈希索引可以带来速度提升，则建立哈希索引。其通过缓冲池的 B+ 树页构造而来，建立速度很快，不需要对整张表构建哈希索引。InnoDB 会根据访问的频率和模式自动地为某些热点页建立哈希索引。

    - 要求：对这个页的连续访问模式（查询条件）必须一样；以该模式访问了 100 次；页通过该模式访问了 N 次，其中 N = 页中记录 * 1/16
    - 哈希索引只能用来搜索**等值查询**

- 异步 IO（Async IO）

    - 用户可以在发送一个 IO 请求后立即发送另一个，当全部 IO 请求发送完毕后，等待所有 IO 操作的完成
    - 另一个优势是可以进行 IO Merge 操作，将多个 IO 合并为一个

- 刷新邻接页（Flush Neighbor Page）：当刷新一个脏页时，InnoDB 会检测该页所在区的所有页，如果是脏页，则一起刷新（可以结合 AIO 将多个 IO 写入操作合并为一个）

## 文件

### 参数文件

- 可以通过命令 `mysql --help | grep my.cnf` 来查看启动时读取的配置文件及其顺序

- 动态参数可以在实例运行中修改，通过 `SET` 命令：

    ```sql
    SET 
    [global|session] system_var_name = expr
    [global.|session.] system_var_name = expr
    ```

    全局修改也只是在本次实例生命周期内有效，若想下次启动实例时仍有效，需要去修改参数文件

- 静态参数在整个实例生命周期内都不能修改（只读）

### 日志文件

- **错误日志（error log）**：对 MySQL 的启动、运行、关闭过程进行了记录，不仅包括错误信息，也记录一些警告信息或正确的信息（例如重做日志文件太小）

- **二进制日志（binlog）**：记录了对 MySQL 数据库执行**更改**的所有操作，但是不包括 `SELECT` 和 `SHOW`，因为这类操作没有修改数据本身；但是如果操作没有导致数据发生变化，也可能被写入二进制日志（例如 `UPDATE` 影响了 0 行）

    作用：

    - 恢复
    - 复制：通过执行二进制日志，使远程数据库与本地进行实时同步
    - 审计

    二进制日志默认为缓冲写，通过设置参数 `sync_binlog=1` 可改为同步写；

    如果设置了同步写，但事务未提交时发生了宕机，由于已经写入了二进制日志，无法回滚，可以通过设置参数 `innodb_support_xa=1` 来解决，确保二进制日志和 InnoDB 存储引擎数据文件的同步

    `binlog_format` 参数：

    - `STATEMENT`：记录的是 SQL 语句，复制时直接执行即可

        优点：日志量小，节约磁盘 IO

        缺点：容易主从不同步（例如使用了随机函数，本机自己定义的函数等）

        > 隔离级别带来的问题：==也是 MySQL 默认使用 `REPEATABLE READ` 的隔离级别的原因==
        >
        > 现在有两个：事务 1（删），事务 2（插），隔离级别为 **READ COMMITTED**，`binlog_format` 参数为 `STATEMENT`
        >
        > - 在 master 上执行顺序为先删后插，由于使用了 `STATEMENT` 参数，事务在提交前，二进制日志先缓存，事务提交后才写入记录，**可能在二进制日志中的顺序变为了先插后删**
        > - 在 slave 上执行顺序为先插后删，导致主从不一致
        >
        > 解决方法：
        >
        > 1. 采用 `REPEATABLE READ` 的隔离级别，由于会引入**间隙锁**，在 master 中执行删除时，插入操作会被锁阻塞，从而必然先完成删除事务并先被记录，可以保证 slave 上先删后插
        > 2. 将 `binlog_format` 格式改为 `ROW`，记录的是表中行的更改情况，直接基于行进行复制

    - `ROW`：记录表的行更改情况

        优点：可以使得隔离级别能被安全设置为 `REAP COMMITTED`，获得更好的并发性

        缺点：日志记录量大

    - `MIXED`：混合模式

- **慢查询日志（slow query log）**：帮助定位可能存在问题的 SQL 语句

    - `long_query_time`：慢查询时间阈值（运行时间大于其的语句都将被记录）
    - `long_query_io`：逻辑 IO 次数阈值（逻辑读取包括磁盘和缓冲区的读取）
    - `log_queries_not_using_indexes`：没有使用索引的语句
    - `log_thr-ottle_queries_not_using_indexes`：每分钟允许记录到慢查询日志的且未使用索引的 SQL 语句次数
    - `mysqldumpslow xxxx.log`：分析慢查询日志命令

- **查询日志（log）**：记录了所有对 MySQL 数据库请求的信息，无论这些请求是否得到了正确的执行

### 套接字文件

- 用于 UNIX 系统下本地连接 MySQL 采用 UNIX 域套接字方式

###  pid 文件

- MySQL 实例启动时，会将自己的进程 id 写入文件中

### 表结构定义文件

- 每个表都有 `.frm` 为后缀名的文件，记录了该表的表结构定义（还可以用来存放视图的定义）

### InnoDB 存储引擎文件

InnoDB 存储引擎独有的文件

- 表空间文件：InnoDB 将存储的数据按表空间进行存放
    - `innodb_data_file_path` 设置共享表空间文件路径（可以是多个文件）
    - `innodb_file_per_table` 可以将每个基于 InnoDB 存储引擎的表产生一个独立表空间，后缀名为 `.ibd`，这些单独的表空间文件仅存储该表的**数据、索引和插入缓冲 BITMAP** 等信息，其他信息还是存放在默认的共享表空间中
    
- 重做日志文件：用于实例/介质失败时的复制，保证数据的完整性（**保证了 InnoDB 可以提供可靠的事务**）
    - 每个 InnoDB 存储引擎至少有 1 个重做日志文件组（group），每个文件组下至少有 2 个重做日志文件
    - 在日志组中每个重做日志文件的大小一致，并以**循环写入**的方式运行（先写重做日志文件 1，写到文件的最后时，切换至重做日志文件 2，以此往复循环）
    - 重做日志文件不能太大，会导致恢复时间长；也不能太小，会频繁切换重做日志文件，并且频繁发生 <a href='#asyncCheckpoint'>async checkpoint</a>
    - 重做日志文件的写入也是 <a href='#redoLogBuffer'>缓冲写</a>，但不需要像刷新脏页那样采用 <a href='#doubleWrite'>两次写</a>，因为从重做日志缓冲向磁盘写入时，按 512 字节（一个扇区）的大小进行写入，必定成功
    
    > 二进制日志和重做日志的区别：
    >
    > - 二进制日志会记录所有存储引擎的事务日志，InnoDB 存储引擎的重做日志只记录它自身的事务日志
    > - 二进制日志是**逻辑**日志，记录的是关于一个事务的具体操作内容；重做日志文件记录的是关于每个页的更改（**物理**情况）
    > - 写入时间不同：二进制日志文件仅在每个事务提交前进行提交，即只写磁盘一次，不论这时事务有多大；而对于重做日志文件来说，一个事务进行的过程中，可能在不断地向其中写入重做日志条目

## 表

### 索引组织表

- 在 InnoDB 存储引擎中，表是根据**主键顺序**组织存放的，这种存储方式称为**索引组织表**

- 如果创建表时没有定义主键，则默认会按如下方式选择或创建主键

    - 表中如果有**非空的唯一索引**，则该列为主键
    - 否则，自动创建一个 6 字节大小的指针（rowid 列）

    当表中有多个非空唯一索引时，默认选择建表时第一个定义的非空唯一索引为主键（**定义索引的顺序**，而不是建表时列的顺序）

    > 可以通过 `SELECT _rowid` 来查看单个列为主键时的表主键

### InnoDB 逻辑存储结构

- 所有数据被逻辑地存放在一个空间，称之为表空间，**表空间由段、区、页（块）组成**。

    <img src="https://staticcdn1-5.umiwi.com/epms_ebook/477cdbf69b6e1c07fb775806fb6dfd38.jpg?x-oss-process=image/resize,w_1112,m_lfit" alt="img" style="zoom:33%;" />


- 表空间：独立表空间只存储**数据、索引、插入缓冲的 Bitmap 页**，共享表空间存储其他所有数据，如**回滚（undo）信息、插入缓冲索引页、系统事务信息、二次写缓冲**等。

    > Rollback 后，InnoDB 存储引擎不会收缩共享表空间，但会标记这些 undo 信息为可用空间，下次 undo 可以覆盖


- 段：包括**数据段、索引段、回滚段**等。数据段就是 B+ 树的叶子节点，索引段就是非叶子节点。段的管理由引擎自身完成，用户不能控制。


- 区：**区是由连续的页组成的空间**，任何情况下区大小都为 1MB。为了保证区中页的连续性，InnoDB 一次从磁盘申请 4～5 个区，默认情况下，InnoDB 的页大小为 16KB，所以一个区有 64 个连续的页。

    - 1.0.x 版本后引入压缩页，每个页可以被设置为 2K、4K、8K，对应区中页的数量为 512、256、128。
    - 1.2.x 版本提供参数 `innodb_page_size` 直接修改默认页大小（非压缩页）

    用户启用参数 `innodb_file_per_table` 后，创建的表默认大小为 96 KB，不足 1M，这是因为**在每个段开始时，先用 32 个页大小的碎片页来存放数据**，用完后才开始申请 64 个连续页。这样做的目的是，对于一些小表，或者是 undo 这类的段，开始时申请较少的空间，节省磁盘的容量。


- 页：是 InnoDB 磁盘管理的**最小单位**，默认大小为 16KB。常见的页类型有：数据页、undo 页、系统页、事务数据页、插入缓冲位图页、插入缓冲空闲列表页、未压缩的二进制大对象页（Uncompressed BLOB Page）、压缩的二进制大对象页


- 行：每个页最多存放 16KB/2-200 = 7992 行记录，每个页至少应该有两行记录，否则 B+ 树会退化成链表。如果页中只能存放下一条记录，那么会自动将行数据存放到溢出页中。

### InnoDB 行记录格式

- Compact

  ```
    变长字段长度列表 ｜ NULL 标志位(1B) ｜ 记录头信息(5B) ｜ 列 1 数据 ｜ 列 2 数据 ｜ ...... 
        																							|
    未知(1b) | 未知(1b) | deleted_tag | min_rec_flag | n_owned | heap_no | record_type | next_record
        
  deleted_tag(1b): 该行是否已经被删除
  min_rec_flag(1b): 该记录是否被预先定义为最小的记录
  n_owned(4b): 该记录拥有的记录数
  heap_no(13b): 索引堆中该条记录的排序记录
  record_type(3b): 记录类型，000 表示普通，001 表示 B+ 树节点指针，010 表示 infinum，011 表示 Supremum，1xx 表示保留
  next_record(16b): 页中下一条记录的相对位置
  ```

    - 首部记录变长字段，按照列的顺序**逆序**放置

      - 列的长度小于 255 字节，用 1 字节表示
      - 列的长度大于 255 字节，用 2 字节表示（VARCHAR 最大长度限制为 65535）

      例如：`03 02 01`，代表第一列长度 1，第二列长度 2，第三列长度 3

    - NULL 标志位指示数据中 NULL 值的位置，NULL 除了该标志位，实际存储不占有任何空间

    - 还存在两个隐藏列：**事务 ID 列（6B）和回滚指针列（7B）**，若没有定义主键，还会增加一个 rowid 列（6B）

    - 固定字长 CHAR 字段在未能完全占用其长度空间时，会用 `0x20` 来填充


- Redundant：用于兼容之前版本

  ```
    字段长度偏移列表 ｜ 记录头信息(6B) ｜ 列 1 数据 ｜ 列 2 数据 ｜ 列 3 数据 ｜ ...... 
    										｜
    未知(1b) | 未知(1b) | deleted_tag | min_rec_flag | n_owned | heap_no | n_fields | 1byte_offs_flag | next_record
    
  n_fields(10b): 记录中列的数量，一行最多 1023 列
  1byte_offs_flag(1): 偏移列表为 1 字节还是 2 字节
  ```
  
  - 字段长度偏移列表，同样按照列的顺序**逆序**放置
  - 对于 VARCHAR 类型的 NULL 值，Redundant 行记录格式不占用任何存储空间，而 CHAR 类型的 NULL 值需要占用空间
  - 同样有隐藏列


- 行溢出数据：定义中表示 VARCHAR 列长度最多为 65535，实际上达不到（65532），因为还有别的开销。而且这个 65535 是指字节数（采用 UTF-8 的话实际允许的长度更小），同时是一张表中所有 VARCHAR 列总的字节数。

  - 一页最多 16KB，存放不了 65532 字节，会导致行溢出。数据默认存放在页类型为 B-tree node 中，行溢出时，数据存放在页类型为 Uncompress BLOB 页中，在原始页中，只存放前 768 字节的前缀数据。
  - 如果一个页中至少可以放入两行数据，那 VARCHAR 类型的行数据就不会存放到 BLOB 页中。（长度阈值为 8098）对于 TEXT / BLOB 数据的存放位置，也是如此。


- 1.0.x 开始引入了 file format（新的页格式），以前的 Compact 和 Redundant 称为 Antelope 文件格式，新的文件格式称为 Barracuda 文件格式，其拥有两种新的行记录格式：Compressed 和 Dynamic。
    - 新的两种记录格式对于 BLOB 数据采用了完全的行溢出方式，在数据页中只存放 20 字节的指针，实际的数据都存放在 Off Page 中（Compact 和 Redundant 中会存放前 768 个前缀字节）
    - Compressed 行数据会以 zlib 算法进行压缩


- CHAR(N) 中的 N 是字符个数，而不是字节长度，因此对于不同编码来说长度不固定。对于多字节字符编码（如 UTF-8）的 CHAR 数据类型的存储，InnoDB 存储引擎在内部将其视为变长字符类型，这也就意味着在变长长度列表中会记录 CHAR 数据类型的长度（对于未能占满长度的字符还是填充 `0x20`）。

    > 因此，可以认为在多字节字符集的情况下，CHAR 和 VARCHAR 的实际行存储基本没有区别

### InnoDB 数据页结构

- File Header（文件头）：38 字节
- Page Header（页头）：56 字节
- Infimun 和 Supremum Records：每个数据页都有两个虚拟的行记录，用来限定记录的边界，Infimum 记录比该页中任何主键值都小的值，Supremum 记录比任何可能大的值还要大的值。这两个值在页创建时被建立，并且在任何情况下不会被删除。
- User Records（用户记录，即行记录）
- Free Space（空闲空间）
- Page Directory（页目录）：存放记录的相对位置，记录指针（槽）可能包含多个记录。用户通过 B+ 数索引找到记录所在的页，再通过在 Page Directory 中进行二分查找，找到具体的记录。
- File Trailer（文件结尾信息）：8 字节，用于检测页的完整性

### Named File Formats 机制

用于解决不同版本下页结构兼容性的问题

### 约束

- Innodb 提供：Primary Key、Unique Key、Foreign Key、Default、NOT NULL

- 约束与索引的区别：当用户创建了一个唯一索引，就也创建了一个唯一的约束。但约束更是一个逻辑的概念，用来保证数据的完整性，而索引是一个数据结构，既有逻辑上的概念，在数据库中还代表着物理存储的方式。

- 默认情况下，MySQL 数据库允许非法的或不正确的数据的插入或更新，又或者可以在数据库内部将其转化为一个合法的值，可以通过设置参数 `sql_mode='STRICT_TRANS_TABLES'` 来严格审核输入的参数。

- MySQL 数据库不支持传统的 CHECK 约束，但是通过 ENUM 和 SET 类型可以解决部分这样的约束需求（仅限于离散值）。

- MyISAM 存储引擎本身不支持外键（仅起到注释作用），InnoDB 则完整支持。对参照表的操作定义有：CASCADE、SET NULL、NO ACTION、RESTRICT（默认）。在 InnoDB 中，建立外键会自动地对该列加上一个索引，可以很好地避免外键列上无索引而导致的死锁问题。

    > MySQL 中 NO ACTION、RESTRICT 都是抛出错误，不允许操作发生。这是因为 MySQL 中是即时检查而不是运行完成后的延时检查。

### 视图

- 是基于基表的一个虚拟表，在更新时可以通过 `WITH CHECK OPTION` 选项防止不满足视图定义的更新。
- 物化视图：是一种预先计算后存储好的实体表，例如保存多表连接或聚集等耗时的结果。MySQL 中不支持，Oracle 支持。

### 分区表

- 分区功能不是在存储引擎层完成的，MyISAM、NDB、InnoDB 都支持，CSV、FEDORATED、MEGRE 等就不支持。

- 分区的过程是将一个表或索引分解为多个更小、更可管理的部分。从逻辑上讲，只有一个表或一个索引，但是在物理上这个表或索引可能由数十个物理分区组成，每个分区都是独立的对象，可以独自处理，也可以作为一个更大的对象的一部分进行处理。

- MySQL 只支持水平分区，并不支持垂直分区。

- MySQL 数据库的分区是局部分区索引，一个分区中既存放了数据又存放了索引；全局分区是指，数据存放在各个分区中，但是所有数据的索引放在一个对象中

- MySQL 支持的分区类型：RANGE、LIST、HASH、KEY、COLUMNS。不论创建何种类型的分区，如果表中存在主键或唯一索引时，分区列必须是唯一索引的一个组成部分

    - RANGE：范围

    - LIST：离散范围

    - HASH：指定 Hash 函数

    - KEY：使用 MySQL 数据库提供的函数

    - COLUMNS：可以对非整型的数据进行分区

        RANGE/LIST COLUMNS：可以使用多个列进行分区

- 子分区（复合分区）在分区的基础上再进行分区。MySQL 允许在 RANGE 和 LIST 的分区上再进行 HASH 或 KEY 的子分区。

- MySQL 允许对 NULL 值做分区，对于不同的分区类型，处理方式也不同。MySQL 视 NULL 值小于任何一个非 NULL 值

    - RANGE：放入最左边分区
    - LIST：必须显式指定在哪个分区中存放 NULL 值
    - HASH/KEY：任何 NULL 值记录返回 0

## 索引与算法

### InnoDB 存储引擎索引概述

- B+ 树索引：并不能找到一个给定键值的具体行，只能查找数据行所在的页，然后把页读入到内存，再在内存中进行查找，最后得到要查找的数据
- 哈希索引：InnoDB 中是自适应的，会根据表的情况自动为表生成哈希索引
- 全文索引

### B+ 树

B+ 树是为磁盘或其他直接存取辅助设备设计的一种平衡查找树。在 B+ 树中，所有记录节点都是按键值的大小**顺序存放**在**同一层**的**叶子节点**上，由各叶子节点**指针**进行连接。

#### 插入操作

| Leaf Page 满 | Index Page 满 | 操作                                                         |
| :----------: | :-----------: | :----------------------------------------------------------- |
|      No      |      No       | 直接将记录插入到叶子节点                                     |
|     Yes      |      No       | 1）拆分 Leaf Page<br />2）将中间的节点放入到 Index Page 中<br />3）小于中间节点的记录放左边<br />4）大于或等于中间节点的记录放右边 |
|     Yes      |      Yes      | 1）拆分 Leaf Page<br />2）小于中间节点的记录放左边<br />3）大于或等于中间节点的记录放右边<br />4）拆分 Index Page<br />5）小于中间节点的记录放左边<br />6）大于中间节点的记录放右边<br />7）中间节点放入上一层 |

旋转：发生在 Leaf Page 已经满，但是其左右兄弟节点没有满的情况下

#### 删除操作

B+ 树使用填充因子来控制树的变化，50% 是填充因子可设的最小值

| 叶子节点小于填充因子 | 中间节点小于填充因子 | 操作                                                         |
| :------------------: | :------------------: | ------------------------------------------------------------ |
|          No          |          No          | 直接将记录从叶子节点删除，如果该节点还是 Index Page 的节点，用该节点的右节点代替 |
|         Yes          |          No          | 合并叶子节点和它的兄弟节点，同时更新 Index Page              |
|         Yes          |         Yes          | 1）合并叶子节点和它的兄弟节点<br />2）更新 Index Page<br />3）合并 Index Page 和它的兄弟节点 |

### B+ 树索引

- B+ 索引在数据库中的一个特点是**高扇出性**，在数据库中 B+ 树的高度一般都在 2～4 层层，因此查找一个键值的行记录最多需要 2～4 次 IO。

- **聚集索引**：**按主键构造的 B+ 树，叶子节点（数据页）中存放的为整张表的行记录数据。**由于实际的数据页只能按照一棵 B+ 树进行排序，因此每张表只能拥有一个聚集索引。

    在多数情况下，查询优化器倾向于采用聚集索引。因为聚集索引能够在 B+ 树索引的叶子节点上直接找到数据。此外，由于定于了数据的逻辑顺序，**聚集索引能够特别快地访问针对范围值的查询，和对主键的排序查找**。查询优化器能够快速发现某一段范围的数据页需要扫描。

    聚集索引的存储并不是物理上连续的，而是逻辑上连续的。

- **辅助索引（非聚集索引）**：**叶子节点并不包含行记录的全部数据。**叶子节点除了包含键值以外，每个叶子节点中的索引行中还包含了一个书签，该书签用来告诉 InnoDB 哪里可以找到与索引相对应的行数据。由于 InnoDB 存储引擎表是索引组织表，因此其辅助索引的书签就是相应行数据的聚集索引键。

    辅助索引的存在并不影响数据在聚集索引中的组织，因此每张表上可以有多个辅助索引。当通过辅助索引来寻找数据时，InnoDB 存储引擎会遍历辅助索引并通过叶级别的指针获得指向主键索引的主键，然后再通过主键索引来找到一个完整的行记录。

    > 举例来说，如果在一棵高度为 3 的辅助索引树中查找数据，那需要对这棵辅助索引树遍历 3 次找到指定主键，如果聚集索引树的高度同样为 3，那么还需要对聚集索引树进行 3 次查找，最终找到一个完整的行数据所在的页，因此一共需要 6 次逻辑 IO 访问以得到最终的一个数据页。

### Cardinality 值

- 在访问表中很少一部分时使用 B+ 树索引才有意义，Cardinality 值表示索引中不重复记录数量的预估值，在实际使用中，`Cardinality / n_rows_in_table` 应尽可能接近 `1`

- 对 Cardinality 的统计是放在存储引擎层进行的，通过采样的方法来完成。

- Cardinality 统计信息的更新发生在两个操作中：INSERT 和 UPDATE，策略为：

    - 表中 1/16 的数据已发生过变化
    - `stat_modified_counter > 2000000000`，发生变化的次数

    采样是对随机的 8 个叶子节点进行统计

### 使用索引

- 联合索引
  - 对多个列创建索引
  - 可以优化联合查询，或者单列查询（如果在 B+ 树是有序存储的话）
- 覆盖索引
  - 覆盖索引是从辅助索引中就可以得到查询的记录，而不需要查询聚集索引中的记录。使用覆盖索引的一个好处是辅助索引不包含整行记录的所有信息，故其大小要远小于聚集索引，因此可以减少大量的 IO 操作。
- 优化器不使用索引的情况：大多为范围查找、JOIN 链接操作等

### 哈希索引

- InnoDB 的哈希算法采用链表作为冲突机制，哈希函数采用除法散列方式
- 自适应哈希索引经哈希函数映射到一个哈希表中，因此**对于字典类型的查找非常快速，但对于范围查找就无能为力**

###全文检索

- B+ 树索引支持通过索引字段的前缀进行查找

- 倒排索引：在**辅助表**中存储了单词与单词自身在一个或多个文档中所在位置之间的映射，通过关联数组实现

    - `inverted file index`：{单词，单词所在文档的 ID}
    - `full inverted index`：{单词，（单词所在文档的 ID，在具体文档中的位置）}

- InnoDB 的全文检索是采用 `full inverted index`，在辅助表的单词字段上设有索引，每张表只能有一个全文检索的索引

- Auxiliary Table 辅助表是一个持久的表，存放于磁盘上；FTS Index Cache（全文检索索引缓存）是一个红黑树结构，根据（word, ilist）进行排序，缓存对辅助表的更新，在全文检索之前合并更新（类似插入缓存）

- 对于 InnoDB 存储引擎而言，其总是在事务提交时将分词写入到 FTS Index Cache，然后再通过批量更新写入到磁盘。虽然 InnoDB 存储引擎通过一种延时的、批量的写入方式来提高数据库的性能，但是上述操作仅在事务提交时发生。对于删除操作，其在事务提交时，不删除磁盘 Auxiliary Table 中的记录，而只是删除 FTS Cache Index 中的记录。

- 全文检索查询语法：

    ```mysql
    MATCH(col1,col2,...)
    AGAINST(expr[search_modifier])
    
    search_modifier: {
      IN NATURAL LANGUAGE MODE
    | IN NATURAL LANGUAGE MODE WITH QUERY EXPANSION
    | IN BOOLEAN MODE -- 是否使用修饰符
    | WITH QUERY EXPANSION
    }
    ```

## 锁

- InnoDB 存储引擎锁的实现和 Oracle 数据库非常类似，提供一致性的非锁定读、行级锁支持。行级锁没有相关额外的开销，并可以同时得到并发性和一致性。
- latch：轻量级的锁，对象是线程，要求锁定的时间必须非常短。在 InnoDB 中，latch 分为 mutex（互斥锁）和 rwlock（读写锁），其目的是用来保证并发线程操作临界资源的正确性，并且通常没有死锁检测的机制。
- lock：对象是事务，用来锁定的是数据库中的对象，如表、页、行。并且一般 lock 的对象仅在事务 commit 或 rollback 后进行释放（不同事务隔离级别释放的时间可能不同），有死锁检测与处理机制。

### InnoDB 存储引擎中的锁

- 行级锁：

    - **共享锁**（S Lock）：允许事务读一行数据
    - **排他锁**（X Lock）：允许事务删除或更新一行数据

- 意向锁：InnoDB 存储引擎支持多粒度（granular）锁定，这种锁定允许事务在行级上的锁和表级上的锁同时存在。意向锁是将锁定的对象分为多个层次，意味着事务希望在更细粒度（fine granularity）上进行加锁。

    对最下层的对象上锁，也就是对最细粒度的对象进行上锁，首先需要对粗粒度的对象上锁。

    > 想要对记录 r 上 X 锁，那么分别需要对数据 A、表、页上意向锁 IX

    InnoDB 支持意向锁设计比较简单，即意向锁为**表级锁**，设计目的主要是为了在一个事务中揭示下一行将被请求的锁类型。

    - **意向共享锁**（IS Lock），事务想要获得一张表中某几行的共享锁
    - **意向排他锁**（IX Lock），事务想要获得一张表中某几行的排他锁

    由于 InnoDB 存储引擎支持的是行级别的锁，因此意向锁其实不会阻塞除全表扫以外的任何请求

- **一致性非锁定读**：指 InnoDB 通过行多版本控制的方式来读取当前执行时间数据库中行的数据。如果读取的行正在执行 DELETE 或 UPDATE 操作，这时读取操作不会因此去等待行上锁的释放。相反地，InnoDB 存储引擎会去**读取行的一个快照数据**。

    之所以称其为非锁定读，因为不需要等待访问的行上 X 锁的释放。快照数据是指该行的之前版本的数据，该实现是通过 undo 段来完成。而 undo 用来在事务中回滚数据，因此快照数据本身是没有额外的开销。

    > 在 READ COMMITTED 事务隔离级别下，对于快照数据，非一致性读总是读取被锁定行的最新一份快照数据。（违反了隔离性）
    >
    > 而在 REPEATABLE READ 事务隔离级别下，对于快照数据，非一致性读总是读取事务开始时的行数据版本。

- **一致性锁定读**：显式加锁，必须在事务中

    ```mysql
    -- 对读取的行记录加 X 锁
    SELECT ... FOR UPDATE
    
    -- 对读取的行记录加 S 锁
    SELECT ... LOCK IN SHARE MODE
    ```

- **自增长锁**：特殊的**表锁**机制，为了提高插入的性能，锁不是在一个事务完成后才释放，而是在完成对自增长值插入的 SQL 语句后立即释放

    - 缺点：对于有自增长值的列的并发插入性能较差，事务必须等待前一个插入的完成（虽然不用等待事务的完成）。其次，对于 INSERT…SELECT 的大数据量的插入会影响插入的性能，因为另一个事务中的插入会被阻塞。
    - 从 MySQL 5.1.22 版本开始，InnoDB 存储引擎中提供了一种**轻量级互斥量**的自增长实现机制，这种机制大大提高了自增长值插入的性能。对于在插入前就可以确定插入行数的语句，会使用互斥量去对内存中的计数器进行累加的操作。

- 外键和锁：对于外键值的插入或更新，首先需要查询父表中的记录，即 SELECT 父表。但是对于父表的 SELECT 操作，**不是使用一致性非锁定读的方式**，因为这样会发生**数据不一致的问题**，因此这时使用的是 SELECT…LOCK IN SHARE MODE 方式，即主动对父表加一个 S 锁。如果这时父表上已经这样加 X 锁，子表上的操作会被阻塞。

    > 事务 A 删除一个数据还未提交，如果采用一致性非锁定读，事务 B 就会读取到该数据，之后事务 A 提交，造成数据不一致。

### 锁算法

- **Record Lock**：单个行记录上的锁，总是会去锁住索引记录，如果 InnoDB 表在建立的时候没有设置任何一个索引，那么此时会使用隐式的主键来进行锁定
- **Gap Lock**：间隙锁，锁定一个范围，但不包含记录本身
- **Next-Key Lock**：Gap Lock + Record Lock，锁定一个范围，并且锁定记录本身。InnoDB 对于行的查询都是采用的这种锁定算法。**（在 REPEATABLE READ 隔离级别下解决幻读问题）**
- 当查询的索引含有唯一属性时，InnoDB 会对 Next-Key Lock 进行优化，将其降级为 Record Lock，即仅锁住索引本身，而不是范围。Next-Key Lock 降级为 Record Lock仅在查询**所有的唯一索引**的情况下（部分的唯一索引列也不行），若是辅助索引，则不会。
- 将事务的隔离级别设置为 READ COMMITTED 可以关闭 Gap Lock
- 在 InnoDB 存储引擎中，对于 INSERT 的操作，其会检查插入记录的下一条记录是否被锁定，若已经被锁定，则不允许查询

### 锁问题

- **脏读**：脏数据是指事务对缓冲池中行记录的修改，并且还没有被提交（commit），一个事务如果可以读到另一个事务中未提交的数据，会违反数据库的隔离性

    > 脏读隔离看似毫无用处，但在一些比较特殊的情况下还是可以将事务的隔离级别设置为 READ UNCOMMITTED。例如 replication 环境中的 slave 节点，并且在该 slave 上的查询并不需要特别精确的返回值。

- **不可重复读**：指在一个事务内多次读取同一数据集合，得到的数据不同，违反了数据库的一致性

    > 不可重复读和脏读的区别是：脏读是读到未提交的数据，而不可重复读读到的却是已经提交的数据，但是其违反了数据库事务一致性的要求。

- **丢失更新**：在当前数据库的任何隔离级别下，都不会导致数据库理论意义上的丢失更新问题。这是因为，即使是 READ UNCOMMITTED 的事务隔离级别，对于行的 DML 操作，需要对行或其他粗粒度级别的对象加锁。

- **阻塞**：因为不同锁之间的兼容性关系，在有些时刻一个事务中的锁需要等待另一个事务中的锁释放它所占用的资源，这就是阻塞。

    > 在默认情况下 InnoDB 存储引擎不会回滚超时引发的错误异常。其实 InnoDB 存储引擎在大部分情况下都不会对异常进行回滚。

### 死锁

- 死锁是指两个或两个以上的事务在执行过程中，因争夺锁资源而造成的一种互相等待的现象。若无外力作用，事务都将无法推进下去。
- 解决方式：
    - 超时回滚：若超时的事务所占权重比较大，如事务操作更新了很多行，占用了较多的 undo log，这时采用 FIFO 的方式，就显得不合适了，因为回滚这个事务的时间相对另一个事务所占用的时间可能会很多。
    - 等待图检测：数据库保存锁的信息链表、事务等待链表，若图中存在回路，就代表存在死锁
- 事务发生死锁的概率与以下几点因素有关：
    - 系统中事务的数量（n），数量越多发生死锁的概率越大。
    - 每个事务操作的数量（r），每个事务操作的数量越多，发生死锁的概率越大。
    - 操作数据的集合（R），越小则发生死锁的概率越大。
- InnoDB 存储引擎并不会回滚大部分的错误异常，但是死锁除外。发现死锁后，InnoDB 存储引擎会马上回滚一个事务

### 锁升级

- 锁升级（Lock Escalation）是指将当前锁的粒度降低。
- 在 Microsoft SQL Server 数据库中，由于锁是一种稀有的资源，因此锁升级会带来一定的效率提高。但是锁升级带来的一个问题却是因为锁粒度的降低而导致并发性能的降低。
- InnoDB 存储引擎不存在锁升级的问题。因为其不是根据每个记录来产生行锁的，相反，其**根据每个事务访问的每个页对锁进行管理**的，采用的是**位图**的方式。因此不管一个事务锁住页中一个记录还是多个记录，其开销通常都是一致的。

## 事务

- ACID

    - A **原子性**：原子性指整个数据库事务是不可分割的工作单位。只有使事务中所有的数据库操作都执行成功，才算整个事务成功。事务中任何一个 SQL 语句执行失败，已经执行成功的SQL语句也必须撤销，数据库状态应该退回到执行事务前的状态。
    - C **一致性**：一致性指事务将数据库从一种状态转变为下一种一致的状态。在事务开始之前和事务结束以后，数据库的完整性约束没有被破坏。
    - I **隔离性**：事务的隔离性要求每个读写事务的对象对其他事务的操作对象能相互分离，即该事务提交前对其他事务都不可见，通常这使用锁来实现。
    - D **持久性**：事务一旦提交，其结果就是永久性的。即使发生宕机等故障，数据库也能将数据恢复。

- 对于 InnoDB 存储引擎而言，其默认的事务隔离级别为 READ REPEATABLE，完全遵循和满足事务的 ACID 特性

- 事务类型

    - **扁平事务**：在扁平事务中，所有操作都处于同一层次，其由 BEGIN WORK 开始，由COMMIT WORK 或 ROLLBACK WORK 结束，其间的操作是原子的，要么都执行，要么都回滚。因此扁平事务是应用程序成为原子操作的基本组成模块。

        扁平事务的主要限制是不能提交或者回滚事务的某一部分，或分几个步骤提交。

    - **带有保存点的扁平事务**：除了支持扁平事务支持的操作外，允许在事务执行过程中回滚到同一事务中较早的一个状态。

    - **链事务**：可视为保存点模式的一种变种。带有保存点的扁平事务，当发生系统崩溃时，所有的保存点都将消失，因为其保存点是易失的（volatile），而非持久的（persistent）。这意味着当进行恢复时，事务需要从开始处重新执行，而不能从最近的一个保存点继续执行。
        链事务的思想是：在提交一个事务时，释放不需要的数据对象，将必要的处理上下文隐式地传给下一个要开始的事务。注意，提交事务操作和开始下一个事务操作将合并为一个原子操作。这意味着下一个事务将看到上一个事务的结果，就好像在一个事务中进行的一样。

        > <img src="https://staticcdn1-5.umiwi.com/epms_ebook/55eac92fe6bff1aace224c68f804910b.jpg?x-oss-process=image/resize,w_1920,m_lfit" alt="img" style="zoom: 50%;" />
        >
        > 链事务与带有保存点的扁平事务不同的是，带有保存点的扁平事务能回滚到任意正确的保存点。而链事务中的回滚仅限于当前事务，即只能恢复到最近一个的保存点。对于锁的处理，两者也不相同。链事务在执行 COMMIT 后即释放了当前事务所持有的锁，而带有保存点的扁平事务不影响迄今为止所持有的锁。

    - **嵌套事务**：是一个层次结构框架。由一个顶层事务（top-level transaction）控制着各个层次的事务。顶层事务之下嵌套的事务被称为子事务（subtransaction），其控制每一个局部的变换。嵌套事务可以支持事务的并行。

        子事务既可以提交也可以回滚。但是它的提交操作并不马上生效，除非其父事务已经提交。因此可以推论出，**任何子事物都在顶层事务提交后才真正的提交**。
        树中的任意一个事务的回滚会引起它的所有子事务一同回滚，故子事务仅保留 A、C、I 特性，不具有 D 的特性。

        > 实际的工作是交由叶子节点来完成的，即只有叶子节点的事务才能访问数据库、发送消息、获取其他类型的资源。而高层的事务仅负责逻辑控制，决定何时调用相关的子事务。
        >
        > InnoDB 不原生支持嵌套事务。

    - **分布式事务**：通常是一个在分布式环境下运行的扁平事务，因此需要根据数据所在位置访问网络中的不同节点。

### 事务的实现

- 隔离性通过**锁**来实现；原子性、一致性、持久性通过 redo log 和 undo log 实现。redo log 为重做日志，用来保证事务的持久性，undo log 用来保证事务的一致性，用于事务回滚及 MVCC 的功能。
- redo 恢复提交事务修改的页操作；undo 回滚行记录到某个特定版本。redo 通常是物理日志，记录的是页的物理修改操作；undo 是逻辑日志，根据每行记录进行记录。
- redo log 基本都是顺序写，且数据库运行期间不需要对其进行读取；undo log 是需要进行随机读写的

#### redo

- 重做日志用来实现事务的持久性，即事务 ACID 中的 D。其由两部分组成：一是内存中的重做日志缓冲（redo log buffer），其是易失的；二是重做日志文件（redo logfile），其是持久的。

- 为了确保每次日志都写入重做日志文件，在每次将重做日志缓冲写入重做日志文件后，InnoDB 存储引擎都需要调用一次 fsync 操作。由于重做日志文件打开并没有使用O_DIRECT 选项，因此重做日志缓冲先写入文件系统缓存。为了确保重做日志写入磁盘，必须进行一次 fsync 操作。由于 fsync 的效率取决于磁盘的性能，因此磁盘的性能决定了事务提交的性能，也就是数据库的性能。

- 和二进制日志的区别：

    > 在MySQL数据库中还有一种二进制日志（binlog），其用来进行 POINT-IN-TIME（PIT）的恢复及主从复制（Replication）环境的建立。从表面上看其和重做日志非常相似，都是记录了对于数据库操作的日志。然而，从本质上来看，两者有着非常大的不同。
    >
    > - 重做日志是在 InnoDB 存储引擎层产生，而二进制日志是在 MySQL 数据库的上层产生的，并且二进制日志不仅仅针对于 InnoDB 存储引擎，MySQL 数据库中的任何存储引擎对于数据库的更改都会产生二进制日志。
    > - 两种日志记录的内容形式不同。MySQL数据库上层的二进制日志是一种逻辑日志，其记录的是对应的 SQL 语句。而 InnoDB 存储引擎层面的重做日志是物理格式日志，其记录的是对于每个页的修改。
    > - 两种日志记录写入磁盘的时间点不同，**二进制日志只在事务提交完成后进行一次写入。而重做日志在事务进行中不断地被写入**，这表现为**日志并不是随事务提交的顺序进行写入的**。

- 在 InnoDB 存储引擎中，重做日志都是以 512 字节进行存储的。这意味着重做日志缓存、重做日志文件都是以块（block）的方式进行保存的，称之为重做日志块（redo logblock），每块的大小为 512 字节。由于重做日志块的大小和磁盘扇区大小一样，都是 512 字节，因此重做日志的写入可以保证原子性，不需要 doublewrite 技术。

- 缓存刷新到磁盘的时机：

    - 事务提交时
    - log buffer 中有一半内存空间已经被使用时
    - log checkpoint 时

#### undo

- undo 存放在数据库内部的一个特殊段（undo segment）中，位于共享表空间内。

- undo 是逻辑日志，因此只是将数据库逻辑地恢复到原来的样子。所有修改都被逻辑地取消了，但是数据结构和页本身在回滚之后可能大不相同

- 除了回滚操作，undo 的另一个作用是 MVCC，即在 InnoDB 存储引擎中 MVCC 的实现是通过 undo 来完成。当用户读取一行记录时，若该记录已经被其他事务占用，当前事务可以通过 undo 读取之前的行版本信息，以此实现非锁定读取。

- undo log 会产生 redo log，也就是 undo log 的产生会伴随着 redo log 的产生，这是因为 undo log 也需要持久性的保护

- 当事务提交时，InnoDB 会做以下两件事情：

    - 将 undo log 放入列表中，以供之后的 purge 操作
    - 判断 undo log 所在的页是否可以重用，若可以分配给下个事务使用

    事务提交后并不能马上删除 undo log 及 undo log 所在的页。这是因为可能还有其他事务需要通过 undo log 来得到行记录之前的版本。故事务提交时将 undo log 放入一个链表中，是否可以最终删除 undo log 及 undo log 所在页由 purge 线程来判断。

#### purge

- purge 用于最终完成 delete 和 update 操作
- 为了节省存储空间，InnoDB 存储引擎的 undo log 设计是这样的：一个页上允许多个事务的 undo log 存在。虽然这不代表事务在全局过程中提交的顺序，但是后面的事务产生的 undo log 总在最后。此外，InnoDB 存储引擎还有一个 history 列表，它根据事务提交的顺序，将 undo log 进行链接。这种先从 history lis t中找 undo log，然后再从 undo page 中找 undolog 的设计模式是为了避免大量的随机读取操作，从而提高 purge 的效率。

#### group commit

- 为了提高磁盘 fsync 的效率，当前数据库都提供了 group commit 的功能，即一次 fsync 可以刷新确保多个事务日志被写入文件。

- 事务提交时的两个阶段：

    1. 修改内存中事务对应的信息，并且将日志写入重做日志缓冲。
    2. 调用fsync将确保日志都从重做日志缓冲写入磁盘。

    第二个步骤较慢，而在某个事务进行步骤 2 时，其他事务可以进行步骤 1，可以将多个事务的重做日志通过一次 fsync 刷新到磁盘，这样就大大地减少了磁盘的压力，从而提高了数据库的整体性能。

- 开启二进制日志后，事务的提交步骤：

    1. 当事务提交时 InnoDB 存储引擎进行 prepare 操作。
    2. MySQL 数据库上层写入二进制日志。
    3. InnoDB 存储引擎层将日志写入重做日志文件。
        a）修改内存中事务对应的信息，并且将日志写入重做日志缓冲。
        b）调用 fsync 将确保日志都从重做日志缓冲写入磁盘

### 事务控制语句

- `START TRANSACTION | BEGIN` 显式开启一个事务
- `COMMIT` 提交
- `ROLLBACK` 回滚
- `SAVEPOINT identifier` 创建保存点
- `RELEASE SAVEPOINT identifier` 删除一个保存点
- `ROLLBACK TO[SAVEPOINT] identifier` 回滚到保存点，并没有真正地结束事务
- `SET TRANSACTION` 设置事务的隔离级别

### 分布式事务

- 分布式事务指的是允许多个独立的事务资源参与到一个全局的事务中，全局事务要求在其中的所有参与的事务要么都提交，要么都回滚。
- 在使用分布式事务时，InnoDB 存储引擎的事务隔离级别必须设置为 SERIALIZABLE。
- MySQL 数据库通过内部XA事务保证主从数据一致，保证 binlog 和 redo log 被同时写入（原子）

### 不好的事务习惯

- 不要在循环中 `COMMIT`，因为每次提交都要写一次重做日志
- 使用自动提交（默认配置下 MySQL 总是自动提交）
- 使用自动回滚

